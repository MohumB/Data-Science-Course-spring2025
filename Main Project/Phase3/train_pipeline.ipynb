{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lc6JieVeAFQo","outputId":"b0b6f631-890d-4bc9-89bc-ab5f5fa88fb6","executionInfo":{"status":"ok","timestamp":1749321381796,"user_tz":-210,"elapsed":9682,"user":{"displayName":"MohammadHossein Barabadi","userId":"08282318677652093529"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Data-Science-Course-spring2025'...\n","remote: Enumerating objects: 600, done.\u001b[K\n","remote: Counting objects: 100% (178/178), done.\u001b[K\n","remote: Compressing objects: 100% (110/110), done.\u001b[K\n","remote: Total 600 (delta 76), reused 155 (delta 57), pack-reused 422 (from 1)\u001b[K\n","Receiving objects: 100% (600/600), 80.50 MiB | 14.42 MiB/s, done.\n","Resolving deltas: 100% (228/228), done.\n","Updating files: 100% (112/112), done.\n"]}],"source":["!git clone https://github.com/nelyasi71/Data-Science-Course-spring2025.git"]},{"cell_type":"code","source":["%cd \"/content/Data-Science-Course-spring2025/Main Project/Phase3/scripts\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fdYCvWLpBSGv","outputId":"a49b8c4b-29d1-47bc-fb05-a31b702f54f6","executionInfo":{"status":"ok","timestamp":1749321384247,"user_tz":-210,"elapsed":352,"user":{"displayName":"MohammadHossein Barabadi","userId":"08282318677652093529"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Data-Science-Course-spring2025/Main Project/Phase3/scripts\n"]}]},{"cell_type":"code","source":["!python run_pipeline.py --max-lines 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQjVx4bIMmG6","outputId":"650c49dd-28fc-4849-e6df-123fb3b08c1b","executionInfo":{"status":"ok","timestamp":1749321932908,"user_tz":-210,"elapsed":544616,"user":{"displayName":"MohammadHossein Barabadi","userId":"08282318677652093529"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-06-07 18:36:28,440 - INFO - üöÄ Starting Training Pipeline\n","2025-06-07 18:36:28,441 - INFO - ==================================================\n","2025-06-07 18:36:28,441 - INFO - üîç Validating environment...\n","2025-06-07 18:36:28,441 - INFO - ‚úÖ Environment validation passed\n","2025-06-07 18:36:28,441 - INFO - üì¶ Installing dependencies...\n","2025-06-07 18:41:53,373 - INFO - ‚úÖ Dependencies installed successfully\n","2025-06-07 18:41:53,373 - INFO - üìä Stage 1: Loading and preprocessing data...\n","2025-06-07 18:41:53,651 - INFO - NumExpr defaulting to 2 threads.\n","2025-06-07 18:41:54,000 - INFO - PyTorch version 2.6.0+cu124 available.\n","2025-06-07 18:41:54,001 - INFO - Polars version 1.21.0 available.\n","2025-06-07 18:41:54,002 - INFO - Duckdb version 1.2.2 available.\n","2025-06-07 18:41:54,002 - INFO - TensorFlow version 2.18.0 available.\n","2025-06-07 18:41:54,003 - INFO - JAX version 0.5.2 available.\n","Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 12396.35 examples/s]\n","2025-06-07 18:41:54,217 - INFO - ‚úÖ Data loaded and saved: 100 samples\n","2025-06-07 18:41:54,217 - INFO - üöÄ Stage 2: Training model...\n","2025-06-07 18:45:32,473 - INFO - ‚úÖ Model training completed successfully\n","2025-06-07 18:45:32,473 - INFO - Model saved to: ./llama-lora-finetuned\n","2025-06-07 18:45:32,473 - INFO - üîç Validating trained model...\n","2025-06-07 18:45:32,474 - WARNING - ‚ö†Ô∏è Some model files may be missing: ['config.json', 'pytorch_model.bin']\n","2025-06-07 18:45:32,474 - INFO - Model directory contains 8 files\n","2025-06-07 18:45:32,474 - INFO - üìã Training report saved to: training_report_20250607_184532.json\n","2025-06-07 18:45:32,474 - INFO - üéâ Training pipeline completed in 9.07 minutes\n","2025-06-07 18:45:32,474 - INFO - üéâ Training pipeline completed successfully!\n","\n","‚úÖ SUCCESS: Model trained and saved to ./llama-lora-finetuned\n"]}]}]}