{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b304319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cdd1f",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6595f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rate = pd.read_csv(\"train_data_movie_rate.csv\")\n",
    "movie_trust = pd.read_csv(\"train_data_movie_trust.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d39f88",
   "metadata": {},
   "source": [
    "### Displaying Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e923b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie Ratings Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34298 entries, 0 to 34297\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       34298 non-null  int64  \n",
      " 1   user_id  34298 non-null  int64  \n",
      " 2   item_id  34298 non-null  int64  \n",
      " 3   label    34298 non-null  float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 1.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMovie Ratings Info:\")\n",
    "print(movie_rate.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6b36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie Trust Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1853 entries, 0 to 1852\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   id               1853 non-null   int64\n",
      " 1   user_id_trustor  1853 non-null   int64\n",
      " 2   user_id_trustee  1853 non-null   int64\n",
      " 3   trust_value      1853 non-null   int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 58.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMovie Trust Info:\")\n",
    "print(movie_trust.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34032a3a",
   "metadata": {},
   "source": [
    "### Missing Values and Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb03eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Ratings Dataset:\n",
      "id         0\n",
      "user_id    0\n",
      "item_id    0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Ratings Dataset:\")\n",
    "print(movie_rate.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d8c143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Trust Dataset:\n",
      "id                 0\n",
      "user_id_trustor    0\n",
      "user_id_trustee    0\n",
      "trust_value        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Trust Dataset:\")\n",
    "print(movie_trust.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bedb56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows in Ratings Dataset: 0\n",
      "Duplicate rows in Trust Dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDuplicate rows in Ratings Dataset:\", movie_rate.duplicated().sum())\n",
    "print(\"Duplicate rows in Trust Dataset:\", movie_trust.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c0dfd",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995b83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# movie_rate['label'] = scaler.fit_transform(movie_rate[['label']])\n",
    "# print(movie_rate[['label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69e4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = pd.Index(\n",
    "    pd.concat([\n",
    "        movie_rate['user_id'],\n",
    "        movie_trust['user_id_trustor'],\n",
    "        movie_trust['user_id_trustee']\n",
    "    ]).unique()\n",
    ")\n",
    "user_id_map = {id_: idx for idx, id_ in enumerate(all_user_ids)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bc2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_ids = pd.Index(movie_rate['item_id'].unique())\n",
    "item_id_map = {id_: idx for idx, id_ in enumerate(all_item_ids)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2946aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rate['u'] = movie_rate['user_id'].map(user_id_map)\n",
    "movie_rate['i'] = movie_rate['item_id'].map(item_id_map)\n",
    "\n",
    "movie_trust['u'] = movie_trust['user_id_trustor'].map(user_id_map)\n",
    "movie_trust['v'] = movie_trust['user_id_trustee'].map(user_id_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67fdb128",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert movie_rate[['u', 'i']].isnull().sum().sum() == 0\n",
    "assert movie_trust[['u', 'v']].isnull().sum().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6729c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrustMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        self.trust_factors = nn.Embedding(num_users, embedding_dim)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        user_vec = self.user_factors(u)\n",
    "        item_vec = self.item_factors(i)\n",
    "        return (user_vec * item_vec).sum(1)\n",
    "\n",
    "    def trust_score(self, u, v):\n",
    "        trustor_vec = self.user_factors(u)\n",
    "        trustee_vec = self.trust_factors(v)\n",
    "        return (trustor_vec * trustee_vec).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2b6ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_users = len(user_id_map)\n",
    "num_items = len(item_id_map)\n",
    "embedding_dim = 32\n",
    "\n",
    "model = TrustMF(num_users, num_items, embedding_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "rating_loss_fn = nn.MSELoss()\n",
    "trust_loss_fn = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f885f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_users = torch.LongTensor(movie_rate['u'].values).to(device)\n",
    "rating_items = torch.LongTensor(movie_rate['i'].values).to(device)\n",
    "rating_labels = torch.FloatTensor(movie_rate['label'].values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e67b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_users = torch.LongTensor(movie_trust['u'].values).to(device)\n",
    "trust_others = torch.LongTensor(movie_trust['v'].values).to(device)\n",
    "trust_values = torch.FloatTensor(movie_trust['trust_value'].values).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8a26dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Rating Loss=41.0748, Trust Loss=2.4973\n",
      "Epoch 2: Rating Loss=39.6107, Trust Loss=2.3983\n",
      "Epoch 3: Rating Loss=38.2033, Trust Loss=2.3025\n",
      "Epoch 4: Rating Loss=36.8515, Trust Loss=2.2101\n",
      "Epoch 5: Rating Loss=35.5541, Trust Loss=2.1210\n",
      "Epoch 6: Rating Loss=34.3098, Trust Loss=2.0352\n",
      "Epoch 7: Rating Loss=33.1172, Trust Loss=1.9528\n",
      "Epoch 8: Rating Loss=31.9748, Trust Loss=1.8735\n",
      "Epoch 9: Rating Loss=30.8809, Trust Loss=1.7974\n",
      "Epoch 10: Rating Loss=29.8340, Trust Loss=1.7242\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Rating loss\n",
    "    preds = model(rating_users, rating_items)\n",
    "    rating_loss = rating_loss_fn(preds, rating_labels)\n",
    "\n",
    "    # Trust loss\n",
    "    trust_preds = model.trust_score(trust_users, trust_others)\n",
    "    trust_loss = trust_loss_fn(trust_preds, trust_values)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = rating_loss + 0.01 * trust_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Rating Loss={rating_loss.item():.4f}, Trust Loss={trust_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5c4ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 4.2576\n",
      "Root Mean Squared Error (RMSE): 5.3696\n",
      "Accuracy (within ±0.5): 8.46%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predictions\n",
    "    pred_ratings = model(rating_users, rating_items)\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = torch.mean(torch.abs(pred_ratings - rating_labels))\n",
    "    \n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = torch.sqrt(torch.mean((pred_ratings - rating_labels) ** 2))\n",
    "\n",
    "    # Calculate threshold-based accuracy\n",
    "    threshold = 0.5  # Define a threshold for acceptable difference between actual and predicted\n",
    "    accuracy = torch.mean((torch.abs(pred_ratings - rating_labels) <= threshold).float())\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae.item():.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse.item():.4f}\")\n",
    "print(f\"Accuracy (within ±{threshold}): {accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b8c55",
   "metadata": {},
   "source": [
    "## svd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1876f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m movie_trust \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data_movie_trust.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Prepare the user-item interaction matrix\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m pivot_table \u001b[38;5;241m=\u001b[39m \u001b[43mmovie_rate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m pivot_table \u001b[38;5;241m=\u001b[39m pivot_table\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Fill missing values with 0\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert pivot table to a matrix form for matrix factorization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Narges\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:8414\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[1;34m(self, columns, index, values)\u001b[0m\n\u001b[0;32m   8409\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8410\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   8411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   8412\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[1;32m-> 8414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Narges\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:557\u001b[0m, in \u001b[0;36mpivot\u001b[1;34m(data, columns, index, values)\u001b[0m\n\u001b[0;32m    553\u001b[0m         indexed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data[values]\u001b[38;5;241m.\u001b[39m_values, index\u001b[38;5;241m=\u001b[39mmultiindex)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mindexed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    558\u001b[0m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    559\u001b[0m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    560\u001b[0m ]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Narges\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:4313\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   4270\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4271\u001b[0m \u001b[38;5;124;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[0;32m   4272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;124;03mb    2    4\u001b[39;00m\n\u001b[0;32m   4310\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4311\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[1;32m-> 4313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Narges\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:488\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value)\n\u001b[1;32m--> 488\u001b[0m unstacker \u001b[38;5;241m=\u001b[39m \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_expanddim\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker\u001b[38;5;241m.\u001b[39mget_result(\n\u001b[0;32m    492\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_values, value_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    493\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Narges\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:136\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_cells \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:\n\u001b[0;32m    129\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the resulting pandas object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    132\u001b[0m         PerformanceWarning,\n\u001b[0;32m    133\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    134\u001b[0m     )\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Narges\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:188\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m mask\u001b[38;5;241m.\u001b[39mput(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_index \u001b[38;5;241m=\u001b[39m comp_index\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the datasets\n",
    "movie_rate = pd.read_csv('train_data_movie_rate.csv')\n",
    "movie_trust = pd.read_csv('train_data_movie_trust.csv')\n",
    "\n",
    "# Prepare the user-item interaction matrix\n",
    "pivot_table = movie_rate.pivot(index='user_id', columns='item_id', values='label')\n",
    "pivot_table = pivot_table.fillna(0)  # Fill missing values with 0\n",
    "\n",
    "# Convert pivot table to a matrix form for matrix factorization\n",
    "R = pivot_table.values\n",
    "user_item_matrix = np.array(R)\n",
    "\n",
    "# Perform SVD on the ratings matrix (Matrix Factorization)\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)  # You can tune the number of components\n",
    "svd_matrix = svd.fit_transform(user_item_matrix)\n",
    "print(f\"SVD explained variance ratio: {svd.explained_variance_ratio_[:5]}\")  # Print first 5 components\n",
    "\n",
    "# Reconstruct the ratings matrix using SVD results\n",
    "reconstructed_matrix = svd.inverse_transform(svd_matrix)\n",
    "\n",
    "# Evaluate the performance of SVD reconstruction\n",
    "mse = mean_squared_error(user_item_matrix, reconstructed_matrix)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Reconstruction RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d7bcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Test RMSE (XGBoost): 0.7931\n",
      "Test MAE (XGBoost): 0.6215\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Create a DataFrame for trust relationships and user-item interaction\n",
    "movie_trust['trust_value'] = movie_trust['trust_value'].fillna(0)  # Fill missing trust values\n",
    "movie_rate = movie_rate.rename(columns={'user_id': 'user_id_trustor', 'item_id': 'item_id_rate', 'label': 'rating_value'})\n",
    "\n",
    "# Merge trust data with ratings data\n",
    "df = pd.merge(movie_rate, movie_trust, how='left', left_on='user_id_trustor', right_on='user_id_trustor')\n",
    "\n",
    "# Prepare the dataset for training the machine learning model\n",
    "X = df[['user_id_trustor', 'item_id_rate', 'trust_value']]  # Features: user, item, trust\n",
    "y = df['rating_value']  # Target: ratings\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to DMatrix (XGBoost's optimized data structure)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set hyperparameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(dtest)\n",
    "\n",
    "# Calculate RMSE on the test set\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(f\"Test RMSE (XGBoost): {rmse:.4f}\")\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"Test MAE (XGBoost): {mae:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7aa787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (within ±0.5): 47.42%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Already predicted: preds = model.predict(dtest)\n",
    "\n",
    "# Calculate accuracy (within ±0.5)\n",
    "tolerance = 0.5\n",
    "correct_predictions = np.abs(preds - y_test.values) <= tolerance\n",
    "accuracy = np.mean(correct_predictions) * 100  # in percentage\n",
    "\n",
    "print(f\"Accuracy (within ±0.5): {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
